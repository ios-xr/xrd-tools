#!/usr/bin/env python3

# Copyright 2020-2024 Cisco Systems Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# pylint: disable=subprocess-run-check

"""
Check that the host is set up correctly for running XRd containers.
"""

import sys


if sys.version_info < (3, 7):
    print(
        "Your python version {} has reached end-of-life.\n"
        "Please ensure you have 'python3' at version 3.7 or higher on your "
        "PATH (check with 'python3 --version').".format(
            ".".join(str(x) for x in sys.version_info[:2]),
        ),
        file=sys.stderr,
    )
    sys.exit(1)

# pylint: disable=wrong-import-position
import argparse
import enum
import functools
import glob
import os
import re
import shlex
import subprocess
import textwrap
from dataclasses import dataclass
from pathlib import Path
from typing import (
    Any,
    Callable,
    Dict,
    List,
    Mapping,
    NamedTuple,
    NoReturn,
    Optional,
    Set,
    Tuple,
    Union,
)


# pylint: enable=wrong-import-position


# -----------------------------------------------------------------------------
# Globals
# -----------------------------------------------------------------------------


# Exit codes
EXIT_SUCCESS = 0
EXIT_ERROR = 1


INOTIFY_RECOMMENDED = 64000
INOTIFY_PER_CONTAINER = 4000

SUPPORTED_ARCHES = ["x86_64"]

XRD_CP_RAM_GB_PER_CONTAINER = 2
VROUTER_RAM_GB_PER_CONTAINER = 5

SHARED_MEM_MAX_PAGE_SIZE_GB = 2

MIN_CPU_CORES_AVAILABLE = 2

HUGEPAGE_MEMORY_GB = 3
WARNING_HUGEPAGE_SIZE_MB = 2
ACCEPTED_HUGEPAGE_SIZE_GB = 1
ACCEPTED_HUGEPAGE_SIZE_MB = ACCEPTED_HUGEPAGE_SIZE_GB * 1024

MIN_MEMLOCK_GB = 2

REGULAR_STYLE = 0
BOLD_STYLE = 1

REQUIRED_CGROUP_MOUNTS = ["systemd", "memory", "pids", "cpu", "cpuset"]

AMAZON_LINUX_CPE_RGX = r"^cpe:.*:o:amazon:amazon_linux"

DASHED_LINE = "----------------------------------------------------------------------------"
DOUBLE_DASHED_LINE = "============================================================================"

# Kernel parameter values which XRd expects and has been tested with.
MODULE_EXPECTED_PARAMS = {
    "vfio-pci": {
        "nointxmask": ["N"],
        "disable_idle_d3": ["N"],
        "enable_sriov": ["N"],
    },
    "igb_uio": {
        "intr_mode": ["msix", "(null)"],
    },
}

# Global variable for caching result of check of base OS for Amazon Linux.
_is_amazon_linux_cache = None

# -----------------------------------------------------------------------------
# Colours
# -----------------------------------------------------------------------------


def _colour(string: str, colour_code: int, style: int = REGULAR_STYLE) -> str:
    if (
        hasattr(sys.stdout, "isatty")
        and sys.stdout.isatty()
        and os.environ.get("TERM") != "dumb"
    ):
        return f"\033[{style};{colour_code}m{string}\033[0m"
    else:
        return string


def white(string: str) -> str:
    return string


def red(string: str) -> str:
    return _colour(string, 31, BOLD_STYLE)


def green(string: str) -> str:
    return _colour(string, 32)


def yellow(string: str) -> str:
    return _colour(string, 33)


def cyan(string: str) -> str:
    return _colour(string, 36)


def purple(string: str) -> str:
    return _colour(string, 35)


# -----------------------------------------------------------------------------
# Helpers
# -----------------------------------------------------------------------------

_CMD = Union[str, List[str]]


class AppArmorStatus(enum.Enum):
    """
    An Enum class to indicate the status of AppArmor and the `xrd-unconfined`
    profile from the check.

    """

    DISABLED = enum.auto()
    NO_PROFILE = enum.auto()
    ENABLED_WITH_PROFILE = enum.auto()


class CmdTimeoutError(Exception):
    """
    This is so that command timeouts can be handled separately to other
    subprocess.SubprocessError errors.

    """

    def __init__(self, cmd: _CMD):
        super().__init__()
        self.cmd = cmd if type(cmd) is str else " ".join(cmd)

    def __str__(self) -> str:
        return f"Timed out while executing command: {self.cmd}"


def run_cmd(
    cmd: _CMD,
    *,
    timeout: int = 5,
    check: bool = True,
    **kwargs: Any,
) -> Tuple[str, str]:
    """
    Run a subprocess command.

    :param cmd:
        Command to run (as a list of strings, unless 'shell=True' is given).
    :param kwargs:
        Other keyword arguments passed to 'subprocess.run()'.
    :raise subprocess.SubprocessError:
        If calling the command fails or times out.
    :return:
        A tuple of the stdout and stderr from the command.
    """
    # Don't try to pass in `universal_newlines`, because if it's set to false,
    # this function would return bytes rather than strings.
    if "universal_newlines" in kwargs:
        raise TypeError(
            "run_cmd() got unexpected keyword 'universal_newlines'"
        )

    default_kwargs = dict(
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        universal_newlines=True,
        timeout=timeout,
        check=check,
    )
    kwargs = {**default_kwargs, **kwargs}
    try:
        ret = subprocess.run(cmd, **kwargs)
    except subprocess.TimeoutExpired as exc:
        raise CmdTimeoutError(exc.cmd) from exc
    return ret.stdout, ret.stderr


def cmd_is_ok(cmd: _CMD, *args: Any, **kwargs: Any) -> bool:
    """
    Run a command and return True if returning zero or False if the command
    errors.

    A single string command is taken as a shell command whereas a list is a
    direct command where the first element is the executable.
    """
    is_shell = isinstance(cmd, str)
    try:
        run_cmd(cmd, *args, shell=is_shell, **kwargs)
        return True
    except subprocess.SubprocessError:
        return False


def print_heading(heading: str) -> None:
    """
    Print a heading with borders.

    :param heading:
        The heading to print.
    """
    print(
        "==============================\n"
        + heading
        + "\n=============================="
    )


def print_subheading(subheading: str) -> None:
    """
    Print a subheading with borders.

    :param subheading:
        The subheading to print.
    """
    print("\n" + subheading + "\n-----------------------")


def _is_module_installed(module: str) -> bool:
    """
    Check if a module is named in any of the listed modules.
    """
    return cmd_is_ok(f"grep -q /{module}.ko /lib/modules/*/modules.*")


def _is_module_builtin(module: str) -> bool:
    """
    Check if a module is listed as a builtin kernel module
    """
    return cmd_is_ok(f"grep -q /{module}.ko /lib/modules/*/modules.builtin")


def _is_module_loaded(module: str) -> bool:
    """
    Check if a module is loaded (with modprobe) using lsmod.

    NOTE: Be careful that the module may using underscores instead of hyphens
    in lsmod (uses /proc/modules for data.)
    """
    return cmd_is_ok(f"lsmod | grep -q '^{module} '")


def _mount_exists(path: str, *, type_: Optional[str] = None) -> bool:
    """Check whether the specified mount exists."""
    cmd = ["findmnt", path]
    if type_:
        cmd.extend(["-t", type_])
    proc = subprocess.run(
        cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=5
    )
    return proc.returncode == 0


def _get_cgroup_version() -> int:
    """
    Find the cgroup version in use by inspecting /sys/fs/cgroup/.

    :return:
        The cgroup version in use, either 1 or 2.
    """
    if (  # pylint: disable=consider-using-with,unspecified-encoding
        _mount_exists("/sys/fs/cgroup", type_="cgroup2")
        and len(
            open(os.path.join("/sys/fs/cgroup", "cgroup.controllers")).read()
        )
        > 0
    ):
        return 2
    elif any(
        _mount_exists(subpath, type_="cgroup")
        for subpath in glob.glob(os.path.join("/sys/fs/cgroup", "*"))
    ):
        return 1
    else:
        raise Exception("Unable to detect cgroup version in use")


def is_amazon_linux() -> bool:
    """Detect if the host is running Amazon Linux."""
    global _is_amazon_linux_cache

    if _is_amazon_linux_cache is not None:
        return _is_amazon_linux_cache

    cpe_path = Path("/etc/system-release-cpe")
    _is_amazon_linux_cache = False
    if cpe_path.exists():
        cpe = cpe_path.read_text(encoding="utf-8").strip()
        if re.match(AMAZON_LINUX_CPE_RGX, cpe):
            _is_amazon_linux_cache = True

    return _is_amazon_linux_cache


# -----------------------------------------------------------------------------
# Checks
# -----------------------------------------------------------------------------


class CheckState(enum.Enum):
    """The result state of a check."""

    # 'success' check states
    SUCCESS = "success"
    NEUTRAL = "neutral"
    # 'warning' check states
    WARNING = "warning"
    # 'failure' check states
    SKIPPED = "skipped"
    FAILED = "failed"
    # Check state for when the check fails to run/errors
    # Note: this is not 'success', 'warning' or 'failure'
    ERROR = "error"

    def is_failure(self) -> bool:
        """
        Returns True for check states that are classed as 'failure'.
        Note: errors (CheckState.ERROR) are treated as separate.
        """
        return self in [
            CheckState.FAILED,
            CheckState.SKIPPED,
        ]


CheckFuncReturn = Optional[Tuple[CheckState, str]]


# -------------------------------------
# Base checks
# -------------------------------------


def check_arch() -> CheckFuncReturn:
    """Check the architecture is as required."""
    try:
        output, _ = run_cmd(["uname", "-m"])
        arch = output.strip()
        if arch not in SUPPORTED_ARCHES:
            return (
                CheckState.FAILED,
                f"The CPU architecture is {arch}, but XRd only supports: "
                f"{', '.join(SUPPORTED_ARCHES)}.",
            )
    except subprocess.SubprocessError:
        return (
            CheckState.ERROR,
            "Unable to check the CPU architecture with 'uname -m'.\n"
            "XRd supports the following architectures: "
            f"{', '.join(SUPPORTED_ARCHES)}.",
        )

    return CheckState.SUCCESS, arch


def check_cpu_cores() -> CheckFuncReturn:
    """Check the number of available CPU cores is sufficient."""
    expected_cpus_msg = (
        f"At least {MIN_CPU_CORES_AVAILABLE} CPU cores are required."
    )
    cmd = "lscpu"
    try:
        output, _ = run_cmd([cmd])
        match = re.search(r"CPU\(s\):\s+(\d+)\s+", output)
        if not match:
            return (
                CheckState.ERROR,
                f"Unable to parse the output from {cmd!r} -\n"
                "unable to check the number of available CPU cores.\n"
                + expected_cpus_msg,
            )
        available_cpus = int(match.group(1))
        if available_cpus < MIN_CPU_CORES_AVAILABLE:
            return (
                CheckState.FAILED,
                f"The number of available CPU cores is {available_cpus},\n"
                f"but at least {MIN_CPU_CORES_AVAILABLE} CPU cores are required.",
            )
    except subprocess.SubprocessError:
        return (
            CheckState.ERROR,
            f"Error running {cmd!r} to check the number of available CPU cores.\n"
            + expected_cpus_msg,
        )

    return CheckState.SUCCESS, str(available_cpus)


def check_kernel_version() -> CheckFuncReturn:
    """Check kernel version is recent enough."""
    cmd = "uname -r"
    try:
        output, _ = run_cmd(shlex.split(cmd))
        version = ".".join(output.strip().split(".")[:2])
        version_tuple = tuple(int(x) for x in version.split("."))

    except Exception:
        return (
            CheckState.ERROR,
            f"Unable to check the kernel version with command {cmd!r} - must be at least version 4.6",
        )

    if version_tuple < (4, 6):
        return (
            CheckState.FAILED,
            f"The kernel version is {version}, but at least version 4.6 is required.",
        )

    # Check for RHEL/CentOS 8.3 kernel version

    if ".el8" in output and "4.18.0-240." in output:
        return (
            CheckState.FAILED,
            "The operating system appears to be RHEL/CentOS 8.3 "
            "(kernel version 4.18.0-240),\n"
            "which is not supported due to a kernel bug.\n"
            "Please upgrade/downgrade to a RHEL/CentOS "
            "version higher or lower than 8.3",
        )

    return CheckState.SUCCESS, version


def check_base_kernel_modules() -> CheckFuncReturn:
    """Check the required base kernel modules are installed (not necessarily loaded)."""

    base_modules = ("dummy", "nf_tables")
    missing_modules = [
        mod for mod in base_modules if not _is_module_installed(mod)
    ]

    if len(missing_modules) > 0:
        return (
            CheckState.FAILED,
            "Missing kernel module(s): "
            + ", ".join(missing_modules)
            + "\n(checked in /lib/modules/*/modules.*)."
            + "\nIt may be possible to install using your distro's package manager.",
        )

    return CheckState.SUCCESS, "Installed module(s): " + ", ".join(
        base_modules
    )


def check_cgroups() -> CheckFuncReturn:
    """Check cgroups are correctly set up, also checking cgroups version."""
    try:
        version = _get_cgroup_version()
    except Exception:
        return (
            CheckState.ERROR,
            "Error trying to determine the cgroups version - /sys/fs/cgroup is expected to\n"
            "contain cgroup v1 mounts.",
        )

    assert version in (1, 2)

    if version == 1:
        not_exist_mounts = [
            cgrp_dir
            for cgrp_dir in REQUIRED_CGROUP_MOUNTS
            if not _mount_exists(f"/sys/fs/cgroup/{cgrp_dir}", type_="cgroup")
        ]
        if not_exist_mounts:
            fail_msg = (
                f"These cgroup mounts do not exist on the host: {', '.join(not_exist_mounts)}."
                "\nThese mounts are required to run XRd."
            )
            if "systemd" in not_exist_mounts:
                fail_msg += (
                    "\nIf your distro doesn't use systemd, manually add the systemd cgroup mount with:"
                    "\n    sudo mkdir /sys/fs/cgroup/systemd"
                    "\n    sudo mount -t cgroup -o none,name=systemd cgroup /sys/fs/cgroup/systemd"
                )
            return CheckState.FAILED, fail_msg

    return CheckState.SUCCESS, f"v{version}"


def check_inotify_limits(setting: str) -> CheckFuncReturn:
    """Check that the inotify limits are sufficiently high."""
    fix_msg = (
        f"This can be addressed by adding 'fs.inotify.{setting}={INOTIFY_RECOMMENDED}'\n"
        f"to /etc/sysctl.conf or in a dedicated conf file under /etc/sysctl.d/.\n"
        f"For a temporary fix, run:\n"
        f"  sysctl -w fs.inotify.{setting}={INOTIFY_RECOMMENDED}"
    )
    path = f"/proc/sys/fs/inotify/{setting}"
    try:
        with open(path, "r", encoding="utf-8") as f:
            val = int(f.read().strip())
    except Exception:
        return (
            CheckState.ERROR,
            f"Failed to check inotify resource limits by reading\n"
            f"{path}.\n"
            f"The kernel parameter fs.inotify.{setting} should be set to at least {INOTIFY_PER_CONTAINER}\n"
            f"(sufficient for a single instance) - the recommended value is {INOTIFY_RECOMMENDED}.\n"
            + fix_msg,
        )

    if val < INOTIFY_PER_CONTAINER:
        return (
            CheckState.FAILED,
            f"The kernel parameter fs.inotify.{setting} is set to {val} but\n"
            f"should be at least {INOTIFY_PER_CONTAINER} (sufficient for a single instance) - the\n"
            f"recommended value is {INOTIFY_RECOMMENDED}.\n" + fix_msg,
        )
    elif val < INOTIFY_RECOMMENDED:
        return (
            CheckState.WARNING,
            f"The kernel parameter fs.inotify.{setting} is set to {val} -\n"
            f"this is expected to be sufficient for {val // INOTIFY_PER_CONTAINER} XRd instance(s).\n"
            f"The recommended value is {INOTIFY_RECOMMENDED}.\n" + fix_msg,
        )
    else:
        return (
            CheckState.SUCCESS,
            f"{val} - this is expected to be sufficient for "
            f"{val // INOTIFY_PER_CONTAINER} XRd instance(s).",
        )


def check_core_pattern() -> CheckFuncReturn:
    """XR monitors core files if core pattern is a file path and not a pipe."""
    path = "/proc/sys/kernel/core_pattern"
    try:
        with open(path, "r", encoding="utf-8") as f:
            if f.readline().lstrip().startswith("|"):
                managed_by = "the host"
            else:
                managed_by = "XR"
    except Exception:
        return (
            CheckState.NEUTRAL,
            f"Failed to read {path} - unable to determine\n"
            f"whether core files are managed by XR or the host.",
        )
    return CheckState.NEUTRAL, f"core files managed by {managed_by}"


def check_userspace_aslr() -> CheckFuncReturn:
    """Check ASLR is enabled."""
    recommendation = (
        "It is recommended for this kernel parameter to be set to 2 (full\n"
        "randomization) for security reasons. This can be done by adding\n"
        "'kernel.randomize_va_space=2' to /etc/sysctl.conf or in a dedicated conf\n"
        "file under /etc/sysctl.d/.\n"
        "For a temporary fix, run:\n"
        "  sysctl -w kernel.randomize_va_space=2"
    )
    path = "/proc/sys/kernel/randomize_va_space"
    try:
        with open(path, "r", encoding="utf-8") as f:
            val = int(f.read().strip())
    except Exception:
        return (
            CheckState.ERROR,
            f"Failed to read {path}, which controls ASLR\n"
            f"(Address-Space Layout Randomization).\n" + recommendation,
        )

    if val != 2:
        return (
            CheckState.WARNING,
            f"The kernel paramater kernel.randomize_va_space, which controls ASLR\n"
            f"(Address-Space Layout Randomization), is set to {val}.\n"
            + recommendation,
        )

    return CheckState.SUCCESS, "full randomization"


def _apparmor_and_profle_enabled() -> AppArmorStatus:
    """Check the state of AppArmor and the `xrd-unconfined` profile"""
    try:
        with open(
            "/sys/kernel/security/apparmor/profiles", encoding="utf-8"
        ) as f:
            contents = f.read()
    except FileNotFoundError:
        # If the file is not found, AppArmor is not installed.
        return AppArmorStatus.DISABLED

    # If the file is not empty, AppArmor is running and the file contains a
    # list of the loaded profiles. Verify that the `xrd-unconfined` profile
    # is present.
    if contents != "":
        if "xrd-unconfined" in contents:
            return AppArmorStatus.ENABLED_WITH_PROFILE
        else:
            return AppArmorStatus.NO_PROFILE
    else:
        # In this case, AppArmor is installed but not running on the
        # system.
        return AppArmorStatus.DISABLED


def _selinux_is_enabled() -> bool:
    """True if SELinux is enabled."""
    try:
        with open("/etc/selinux/config", encoding="utf-8") as f:
            contents = f.read()
    except FileNotFoundError:
        # If the file is not found, selinux is not installed.
        return False

    # If the file exists with SELINUX=enforcing, return True. Otherwise if
    # SELINUX=enforcing is not present, that could be because it is either
    # in permissive mode or disabled mode, hence return False.
    return "SELINUX=enforcing" in contents.splitlines()


def check_linux_security_modules() -> CheckFuncReturn:
    """Inform if LSMs AppArmor/SELinux are enabled on the host system."""
    msgs = []
    ch_state = CheckState.NEUTRAL

    apparmor_status = _apparmor_and_profle_enabled()

    if apparmor_status == AppArmorStatus.ENABLED_WITH_PROFILE:
        msgs.append(
            "AppArmor is running with the recommended `xrd-unconfined` profile.\n"
            "XRd is able to run under this profile by running with '--security-opt\n"
            "apparmor=xrd-unconfined', however this is not supported when launching\n"
            "the container in privileged mode."
        )
    elif apparmor_status == AppArmorStatus.NO_PROFILE:
        msgs.append(
            "AppArmor is running on this system but the `xrd-unconfined` profile is\n"
            "not installed / loaded. XRd is unable to run as expected without this\n"
            "profile in place, so please follow the steps from the README.md file\n"
            "at https://github.com/ios-xr/xrd-tools to install and enable the profile."
        )
        ch_state = CheckState.FAILED
    if _selinux_is_enabled():
        msgs.append(
            "SELinux is enabled and enforced. XRd is currently unable to run with the\n"
            "default policy, but can be run with '--security-opt label=disable' or\n"
            "equivalent."
        )

    if not msgs:
        msgs.append("No LSMs are enabled")

    return ch_state, "\n".join(msgs)


def check_realtime_group_sched() -> CheckFuncReturn:
    """Check that real-time group scheduling is disabled"""
    recommendation = (
        "Running with real-time group scheduling enabled is not supported.\n"
        "If real-time group scheduling (RT_GROUP_SCHED) is configured in the kernel,\n"
        "it is required that this feature is disabled at runtime by adding\n"
        "'kernel.sched_rt_runtime_us=-1' to /etc/sysctl.conf or in a dedicated conf\n"
        "file under /etc/sysctl.d/.\n"
        "For a temporary fix, run:\n"
        "  sysctl -w kernel.sched_rt_runtime_us=-1"
    )

    # We've specified a dependency on the Cgroup check, so can assume this will succeed.
    cgroup_version = _get_cgroup_version()

    if cgroup_version == 1:
        rt_runtime_us_path = "/sys/fs/cgroup/cpu/cpu.rt_runtime_us"
    else:
        rt_runtime_us_path = "/sys/fs/cgroup/cpu.rt_runtime_us"

    if os.path.exists(rt_runtime_us_path):
        kernel_sched_rt_path = "/proc/sys/kernel/sched_rt_runtime_us"
        try:
            with open(kernel_sched_rt_path, "r", encoding="utf-8") as f:
                val = int(f.read().strip())
                if val != -1:
                    return (
                        CheckState.FAILED,
                        f"The kernel parameter kernel.sched_rt_runtime_us is set to {val}\n"
                        f"but must be disabled by setting it to '-1'.\n"
                        + recommendation,
                    )
                else:
                    return CheckState.SUCCESS, "disabled at runtime"
        except Exception:
            return (
                CheckState.ERROR,
                f"Failed to read {kernel_sched_rt_path}, unable to check if\n"
                f"real-time group scheduling is disabled.\n" + recommendation,
            )

    return CheckState.SUCCESS, "disabled in kernel config"


def check_socket_parameters() -> CheckFuncReturn:
    """Check that socket kernel parameters are set high enough"""
    required_params = {
        "netdev_max_backlog": 300000,
        "optmem_max": 67108864,
        "rmem_default": 67108864,
        "rmem_max": 67108864,
        "wmem_default": 67108864,
        "wmem_max": 67108864,
    }
    host_params = {}
    bad_values = False
    for param, required_value in required_params.items():
        base_path = "/proc/sys/net/core"
        path = f"{base_path}/{param}"
        try:
            with open(path, "r", encoding="utf-8") as f:
                val = int(f.read().strip())
        except Exception:
            return (
                CheckState.ERROR,
                f"Failed to read socket kernel parameter {path}.",
            )

        host_params[param] = val

        if val < required_value:
            bad_values = True

    if bad_values:
        required_values_str = ""
        host_values_str = ""
        for param in sorted(required_params):
            required_values_str += (
                f"    net.core.{param}={required_params[param]}\n"
            )
            host_values_str += f"    net.core.{param}={host_params[param]}\n"
        return (
            CheckState.WARNING,
            f"The kernel socket parameters are insufficient for running XRd in a\n"
            f"production deployment. They may be used in a lab deployment, but must\n"
            f"be increased to the required minimums for production deployment.\n"
            f"Lower values may result in XR IPC loss and unpredictable behavior,\n"
            f"particularly at higher scale.\n"
            f"\n"
            f"The required minimum settings are:\n"
            f"{required_values_str}\n"
            f"The current host settings are:\n"
            f"{host_values_str}\n"
            f"Values can be changed by adding e.g.\n"
            f"'net.core.rmem_default=67108864' to /etc/sysctl.conf or\n"
            f"in a dedicated conf file under /etc/sysctl.d/.\n"
            f"Or for a temporary fix, running e.g.:\n"
            f"  sysctl -w net.core.rmem_default=67108864",
        )

    return CheckState.SUCCESS, "valid settings"


def check_udp_parameters() -> CheckFuncReturn:
    """Check that socket UDP parameters are set high enough"""

    path = "/proc/sys/net/ipv4/udp_mem"
    try:
        with open(path, "r", encoding="utf-8") as f:
            val = f.read().strip().split()
    except Exception:
        return (
            CheckState.ERROR,
            f"Failed to read UDP kernel parameter {path}.",
        )

    # Values must be at least '1124736 10000000 67108864'

    bad_value = False
    if int(val[0]) < 1124736:
        bad_value = True
    elif int(val[1]) < 10000000:
        bad_value = True
    elif int(val[2]) < 67108864:
        bad_value = True

    if bad_value:
        return (
            CheckState.WARNING,
            f"The kernel UDP parameters are insufficient for running XRd in a\n"
            f"production deployment. They may be used in a lab deployment, but must\n"
            f"be increased to the required minimums for production deployment.\n"
            f"Lower values may result in XR IPC loss and unpredictable behavior,\n"
            f"particularly at higher scale.\n"
            f"\n"
            f"The required minimum settings are:\n"
            f"    net.ipv4.udp_mem=1124736 10000000 67108864\n"
            f"The current host settings are:\n"
            f"    net.ipv4.udp_mem={val[0]} {val[1]} {val[2]}\n"
            f"Values can be changed by adding\n"
            f"'net.ipv4.udp_mem=1124736 10000000 67108864' to /etc/sysctl.conf or\n"
            f"in a dedicated conf file under /etc/sysctl.d/.\n"
            f"Or for a temporary fix, running:\n"
            f"  sysctl -w net.ipv4.udp_mem='1124736 10000000 67108864'",
        )

    return CheckState.SUCCESS, "valid settings"


# -------------------------------------
# Platform checks
# -------------------------------------


def check_ram(ram_req: int) -> CheckFuncReturn:
    """Check there is sufficient RAM."""
    # -b displays the available RAM in bytes
    cmd = "free -b"
    xrd_expected_usage_str = f"Each XRd instance is expected to require {ram_req} GiB of RAM for normal use."

    try:
        output = run_cmd(shlex.split(cmd))[0]
    except subprocess.SubprocessError:
        return (
            CheckState.ERROR,
            f"The command {cmd!r} failed - unable to determine the available RAM on\n"
            f"the host.\n" + xrd_expected_usage_str,
        )

    # Try to parse the available GiB (2^30 bytes)
    # The available memory is displayed in bytes in the last column of the
    # first row of the command output (after headings). Do not include swap,
    # as in general users running XRd should not be depending on swap
    # (although it may be OK in lab cases), but point out that swap may be
    # available.
    try:
        free_mem = int(output.split("\n")[1].split()[-1]) / (2**30)
    except Exception:
        return (
            CheckState.ERROR,
            f"Failed to parse the output from {cmd!r} - unable to determine the\n"
            f"available RAM on the host.\n" + xrd_expected_usage_str,
        )

    if free_mem < ram_req:
        return (
            CheckState.WARNING,
            f"The available RAM on the host ({free_mem:.1f} GiB) may be insufficient to "
            f"run XRd.\n"
            f"{xrd_expected_usage_str}\n"
            f"Note that this does not include any swap that may be available.",
        )

    return (
        CheckState.SUCCESS,
        f"Available RAM is {free_mem:.1f} GiB.\n"
        f"This is estimated to be sufficient for {int(free_mem / ram_req)} "
        f"XRd instance(s), although memory\n"
        f"usage depends on the running configuration.\n"
        f"Note that any swap that may be available is not included.",
    )


def check_cpu_extensions() -> CheckFuncReturn:
    """Check the required CPU extensions are installed."""
    required_cpu_exts = {"ssse3", "sse4_1", "sse4_2"}
    found_cpu_exts = set()
    cmd = "lscpu"
    try:
        output, _ = run_cmd(cmd)
        match = re.search(r"Flags:\s+(.+)", output)
        if not match:
            return (
                CheckState.ERROR,
                f"Unable to parse the output from {cmd!r} - unable to check\n"
                f"for the required CPU extensions: "
                + ", ".join(sorted(required_cpu_exts))
                + "\nAll of these extensions must be installed.",
            )
        cpu_exts = match.group(1).split(" ")
        for ext in required_cpu_exts:
            if ext in cpu_exts:
                found_cpu_exts.add(ext)

        missing_cpu_exts = required_cpu_exts - found_cpu_exts
        if len(missing_cpu_exts) > 0:
            return (
                CheckState.FAILED,
                "Missing CPU extension(s): "
                + ", ".join(sorted(missing_cpu_exts))
                + "\nPlease install the missing extension(s).",
            )
    except subprocess.SubprocessError:
        return (
            CheckState.ERROR,
            f"Unable to parse the output from {cmd!r} - unable to check\n"
            f"for the required CPU extensions: "
            + ", ".join(sorted(required_cpu_exts))
            + "\nAll of these extensions must be installed.",
        )

    return CheckState.SUCCESS, ", ".join(sorted(found_cpu_exts))


def _calc_hugepage_size_and_mem(
    hugepages_lines: List[str],
) -> Tuple[int, float]:
    """Calculates the hugepage size and memory, given the hugepage data."""
    # Returns a list of one string in the format 'label: value unit'
    hugepages_size_line = [s for s in hugepages_lines if "Hugepagesize" in s]
    hugepages_size_string = (
        hugepages_size_line[0].split(":")[-1].strip().split(" ")
    )
    hugepages_size = int(hugepages_size_string[0])
    hugepages_size_unit = hugepages_size_string[1]

    # Convert size to MiB
    if hugepages_size_unit == "kB":
        hugepages_size = hugepages_size // 1024
    elif hugepages_size_unit == "MB":
        pass
    elif hugepages_size_unit == "GB":
        hugepages_size *= 1024

    # Returns a list of one string in the format 'label: value'
    hugepages_free_line = [f for f in hugepages_lines if "Free" in f]
    hugepages_free = int(hugepages_free_line[0].split(":")[-1])
    hugepages_memory = (
        hugepages_free * hugepages_size
    ) / 1024  # calculate available memory in GiB

    return hugepages_size, hugepages_memory


def check_hugepages() -> CheckFuncReturn:
    """Check hugepages are enabled with the required settings."""
    path = "/proc/meminfo"
    msgs = []
    try:
        with open(path, "r", encoding="utf-8") as file:
            hugepages_lines = [
                L for L in file.readlines() if L.startswith("Huge")
            ]
            # Returns a list of one string in the format 'label: value'
            hugepages_total_line = [t for t in hugepages_lines if "Total" in t]
            hugepages_total = int(hugepages_total_line[0].split(":")[-1])

            if hugepages_total == 0:
                return (
                    CheckState.FAILED,
                    "Hugepages are not enabled. These are required for XRd to function correctly."
                    "\nTo enable hugepages, see the instructions at:"
                    "\nhttps://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt.",
                )
            else:
                (
                    hugepages_size,
                    hugepages_memory,
                ) = _calc_hugepage_size_and_mem(hugepages_lines)

            check_state = None
            if hugepages_size == WARNING_HUGEPAGE_SIZE_MB:
                msgs.append(
                    f"{hugepages_size}MiB hugepages are available, but only {ACCEPTED_HUGEPAGE_SIZE_GB}GiB hugepages are\n"
                    "supported for XRd deployment use cases."
                )
                # Just a warning for 2MiB hugepages as they're supported in lab
                # cases
                check_state = CheckState.WARNING
            elif hugepages_size != ACCEPTED_HUGEPAGE_SIZE_MB:
                msgs.append(
                    f"{hugepages_size}MiB hugepages are available, but XRd "
                    f"requires {ACCEPTED_HUGEPAGE_SIZE_GB}GiB hugepages."
                )
                # Fail for any other hugepage size
                check_state = CheckState.FAILED
            if hugepages_memory < HUGEPAGE_MEMORY_GB:
                msgs.append(
                    f"Only {hugepages_memory:.1f}GiB of hugepage memory available, but XRd\n"
                    f"requires at least {HUGEPAGE_MEMORY_GB}GiB."
                )
                # Fail if there's not enough hugepage memory
                check_state = CheckState.FAILED

            if check_state is not None:
                return check_state, "\n".join(msgs)
    except OSError:
        return (
            CheckState.ERROR,
            f"Unable to parse the contents of {path} - unable to check\n"
            f"whether hugepages are enabled with 1GiB (recommended)\n"
            f"or 2MiB hugepage size and at least {HUGEPAGE_MEMORY_GB}GiB of available\n"
            f"hugepage memory.",
        )
    except (ValueError, IndexError):
        return (
            CheckState.ERROR,
            f"Unable to parse the contents of {path} - unable to check\n"
            f"whether hugepages are enabled with 1GiB (recommended)\n"
            f"or 2MiB hugepage size and at least {HUGEPAGE_MEMORY_GB}GiB of available\n"
            f"hugepage memory.",
        )

    hugepages_size = hugepages_size // 1024
    num_hugepgs = int(hugepages_memory // hugepages_size)
    return CheckState.SUCCESS, f"{num_hugepgs} x {hugepages_size}GiB"


@dataclass(frozen=True)
class PCIDriver:
    """
    Class to represent a PCI driver.
    """

    name: str

    def is_supported(self) -> bool:
        # The lsmod, loaded check, requires the underscore version of the kernel
        # module name
        return _is_module_loaded(
            self.name.replace("-", "_")
        ) or _is_module_builtin(self.name)

    def is_installed(self) -> bool:
        return _is_module_installed(self.name)


def check_interface_kernel_driver() -> CheckFuncReturn:
    """Check the required interface specific kernel driver is loaded."""

    pci_drivers = [PCIDriver("vfio-pci"), PCIDriver("igb_uio")]
    supported_drivers = [
        driver for driver in pci_drivers if driver.is_supported()
    ]
    installed_not_supported = [
        driver
        for driver in pci_drivers
        if driver not in supported_drivers and driver.is_installed()
    ]
    supported_str = ", ".join(driver.name for driver in supported_drivers)
    installed_not_supported_str = ", ".join(
        driver.name for driver in installed_not_supported
    )
    # In AWS, must have igb_uio driver available
    if is_amazon_linux():
        if "igb_uio" in supported_str:
            return CheckState.SUCCESS, f"Loaded PCI drivers: {supported_str}"
        elif "igb_uio" in installed_not_supported_str:
            return (
                CheckState.NEUTRAL,
                "igb_uio driver is installed but not loaded.\n"
                "Run 'modprobe igb_uio' to load the driver.",
            )
        else:
            return (
                CheckState.FAILED,
                "The igb_uio PCI driver is not loaded or installed.",
            )
    if supported_drivers:
        if installed_not_supported:
            return (
                CheckState.NEUTRAL,
                f"The following PCI drivers are installed but not loaded: {installed_not_supported_str}.\n"
                f"Loaded PCI drivers: {supported_str}.\n"
                "Run 'modprobe <pci driver>' to load a driver.",
            )
        else:
            return CheckState.SUCCESS, f"Loaded PCI drivers: {supported_str}"
    else:
        if installed_not_supported:
            return (
                CheckState.FAILED,
                "None of the expected PCI drivers are loaded.\n"
                f"The following PCI drivers are installed but not loaded: {installed_not_supported_str}.\n"
                "Run 'modprobe <pci driver>' to load a driver.",
            )
        else:
            return (
                CheckState.FAILED,
                "No PCI drivers are loaded or installed.\n"
                "Must have either the vfio-pci or igb_uio kernel module loaded.\n"
                "It may be possible to install using your distro's package manager.",
            )


def check_iommu() -> CheckFuncReturn:
    """Check IOMMU is set up correctly for the vfio-pci kernel module."""
    if not PCIDriver("vfio-pci").is_supported():
        return CheckState.NEUTRAL, "vfio-pci driver unavailable"

    # In AWS unconditonally succeed as IOMMU cannot be supported.
    if is_amazon_linux():
        return CheckState.NEUTRAL, "IOMMU is not supported in AWS."

    # If igb_uio is supported, treat warnings as info, because even though
    # IOMMU isn't enabled, igb_uio can be used.
    warning_state = CheckState.WARNING
    if PCIDriver("igb_uio").is_supported():
        warning_state = CheckState.NEUTRAL

    recommendation = "IOMMU is recommended for security when using the vfio-pci kernel driver."
    noiommu_filepath = "/sys/module/vfio/parameters/enable_unsafe_noiommu_mode"
    iommu_dev_filepath = "/sys/class/iommu/*/devices/*"

    try:
        with open(noiommu_filepath, "r", encoding="utf-8") as f:
            no_iommu_mode = f.read().strip().upper() in ("Y", "1")
            if no_iommu_mode:
                return (
                    warning_state,
                    "vfio-pci is set up in no-IOMMU mode, but IOMMU is recommended for security.",
                )
    except OSError:
        # If the no-IOMMU file does not exist, then no-IOMMU mode can't be enabled.
        pass

    # Check if IOMMU is enabled on the host
    try:
        iommu_devices = [
            os.path.basename(p) for p in glob.glob(iommu_dev_filepath)
        ]
        if not iommu_devices:  # check if the directory is empty
            return (
                warning_state,
                "The kernel module vfio-pci cannot be used, as IOMMU is not enabled.\n"
                + recommendation,
            )
    except Exception:
        return (
            CheckState.ERROR,
            f"Unable to check if IOMMU is enabled by listing {iommu_dev_filepath}.\n"
            + recommendation,
        )
    return (CheckState.SUCCESS, "IOMMU enabled for vfio-pci.")


def check_pci_devices() -> CheckFuncReturn:
    """Check PCI devices are available."""
    # If only vfio-pci is supported (and it is not in no-IOMMU mode), then
    # check for PCI network devices in IOMMU group, otherwise check for any
    # PCI network devices.
    if (
        PCIDriver("vfio-pci").is_supported()
        and not PCIDriver("igb_uio").is_supported()
    ):
        require_iommu = True
        # Overide require_iommu if no-IOMMU mode is enabled
        noiommu_filepath = (
            "/sys/module/vfio/parameters/enable_unsafe_noiommu_mode"
        )
        try:
            with open(noiommu_filepath, "r", encoding="utf-8") as f:
                if f.read().strip().upper() in ("Y", "1"):
                    require_iommu = False
        except OSError:
            # If the no-IOMMU file does not exist, then no-IOMMU mode can't be
            # enabled.
            pass
    else:
        require_iommu = False

    if require_iommu:
        # Get IOMMU devices
        iommu_dev_filepath = "/sys/class/iommu/*/devices/*"
        try:
            iommu_devices = [
                os.path.basename(p) for p in glob.glob(iommu_dev_filepath)
            ]
        except Exception:
            # If getting the directory fails, then assume IOMMU is not enabled
            iommu_devices = []

    # List the network PCI devices
    try:
        cmd = "lshw -businfo -c network"
        output, _ = run_cmd(shlex.split(cmd))
        matches = re.findall(
            r"pci@([\da-f]{4}:[\da-f]{2}:[\da-f]{2}\.[\da-f])\s+(\S+)", output
        )
        if not matches:
            return CheckState.WARNING, "no PCI network devices found"
        network_devices = set()
        net_devices_dict = {}
        for match in matches:
            bus_info, logical_name = match
            network_devices.add(bus_info)
            net_devices_dict[bus_info] = logical_name

    except subprocess.SubprocessError:
        return (
            CheckState.ERROR,
            f"The cmd {cmd!r} failed - unable to\n"
            "determine the network devices on the host.",
        )

    # If in IOMMU mode then check if the network devices are in the IOMMU group
    if require_iommu:
        network_devices &= set(iommu_devices)
        if not network_devices:
            return (
                CheckState.WARNING,
                "No PCI network devices found with IOMMU enabled for vfio-pci.",
            )

    net_devs_list = []
    for device in sorted(network_devices):
        net_devs_list.append(net_devices_dict[device] + " (" + device + ")")
    dev_output = ""
    for count, dev in enumerate(net_devs_list, start=1):
        if count == len(net_devs_list):
            dev_output = dev_output + f"{dev}"
        elif count % 3 != 0:
            dev_output = dev_output + f"{dev}, "
        else:
            dev_output = dev_output + f"{dev},\n"
    return (
        CheckState.SUCCESS,
        "The following PCI device(s) are available:\n" + dev_output,
    )


def check_shmem_pages_max_size() -> CheckFuncReturn:
    """Check the maximum size of shared memory pages is sufficient."""
    path = "/proc/sys/kernel/shmmax"
    try:
        with open(path, encoding="utf-8") as file:
            contents = file.read().rstrip()  # remove trailing newline
            try:  # try to parse the size in GiB (2^30 bytes)
                shared_mem_max_page_size = int(contents) / (2**30)
            except ValueError:
                return (
                    CheckState.ERROR,
                    f"Unable to parse the contents of {path} - unable to\n"
                    f"determine the maximum size of shared memory pages.\n"
                    f"At least {SHARED_MEM_MAX_PAGE_SIZE_GB} GiB are required.",
                )

            if shared_mem_max_page_size < SHARED_MEM_MAX_PAGE_SIZE_GB:
                return (
                    CheckState.FAILED,
                    f"The maximum size of shared memory pages is {shared_mem_max_page_size:.1f} GiB,\n"
                    f"but at least {SHARED_MEM_MAX_PAGE_SIZE_GB} GiB are required.",
                )
    except OSError:
        return (
            CheckState.ERROR,
            f"Unable to read the contents of {path} - unable to\n"
            f"determine the maximum size of shared memory pages.\n"
            f"At least {SHARED_MEM_MAX_PAGE_SIZE_GB} GiB are required.",
        )

    return CheckState.SUCCESS, f"{shared_mem_max_page_size:.1f} GiB"


def _module_params_compare(
    module: str, exp_param_vals: Dict[str, List[str]]
) -> Dict[str, Optional[str]]:
    """
    For a kernel module, check if the runtime parameters have the expected
    values.

    :param module:
        Name of the module

    :param exp_param_vals:
        Dictionary mapping parameter name to the expected value of the parameter

    :return:
        A dict containing parameters with unexpected values
        If failed to check value for a parameter, returns None as the dict
        value for the parameter
    """
    param_unexpected: Dict[str, Optional[str]] = {}

    if not _is_module_loaded(
        module.replace("-", "_")
    ) and not _is_module_builtin(module):
        # Skip module param check if module is not loaded
        return param_unexpected
    # sysfs filesystem requires the underscore version of the kernel module
    # name
    module = module.replace("-", "_")
    all_params_str, _ = run_cmd(["modinfo", "--field", "parm", module])
    for param, exp_val in exp_param_vals.items():
        if not re.search(rf"^{param}:", all_params_str, re.MULTILINE):
            # if 'param' is absent in modinfo output, it means either the
            # parameter was introduced in a later kernel version, or the
            # specific linux distribution does not support the parameter.
            continue
        try:
            path = f"/sys/module/{module}/parameters/{param}"
            with open(path, "r", encoding="utf-8") as f:
                param_val = f.read().strip()
            if param_val not in exp_val:
                param_unexpected[param] = param_val
        except FileNotFoundError:
            param_unexpected[param] = None

    return param_unexpected


def check_modules_expected_params() -> CheckFuncReturn:
    """
    Checks the kernel modules have been loaded with expected runtime parameters
    (Checks parameters in MODULE_EXPECTED_PARAMS)
    """
    all_modules_str = ""
    for module, param_defaults in MODULE_EXPECTED_PARAMS.items():
        module_str = ""
        param_non_default = _module_params_compare(module, param_defaults)
        for param, param_val in param_non_default.items():
            if param_val is not None:
                module_str += (
                    f"\nThe expected value for parameter {param} is "
                    f"{'/'.join(param_defaults[param])}, but it is set to {param_val}"
                )
            else:
                module_str += f"\nFailed to check value for parameter: {param}"
        if module_str:
            module_str = textwrap.indent(module_str, "   ")
            all_modules_str += f"\nFor kernel module: {module}{module_str}"
    if all_modules_str:
        return (
            CheckState.WARNING,
            "XRd has not been tested with these kernel module parameters."
            + all_modules_str,
        )
    else:
        return (
            CheckState.SUCCESS,
            "Kernel modules loaded with expected parameters.",
        )


# -------------------------------------
# Docker checks
# -------------------------------------


def check_docker_client() -> CheckFuncReturn:
    """Check that the Docker client version is 18.x or higher."""
    cmd = "docker --version"
    try:
        version_str = run_cmd(shlex.split(cmd))[0].strip()
    except (FileNotFoundError, subprocess.SubprocessError):
        return (
            CheckState.FAILED,
            f"Docker client not correctly installed on the host (checked with\n"
            f"{cmd!r}).\n"
            f"See installation instructions at https://docs.docker.com/engine/install/.\n"
            f"At least version 18.0 is required for XRd.",
        )

    version_match = re.match(
        r"Docker version (\d+\.\d+(?:\.\d+)?)", version_str
    )
    if not version_match:
        return (
            CheckState.ERROR,
            f"Unable to parse Docker client version from {cmd!r}.\n"
            f"At least version 18.0 is required for XRd.",
        )
    version = version_match.group(1)

    if int(version.split(".")[0]) < 18:
        return (
            CheckState.FAILED,
            f"Docker version must be at least 18.0, current client version is {version}.\n"
            f"See installation instructions at https://docs.docker.com/engine/install/.",
        )

    return CheckState.SUCCESS, f"version {version}"


def check_docker_daemon() -> CheckFuncReturn:
    """Check that the docker daemon version is at least 18.0."""
    cmd = "docker version -f '{{json .Server.Version}}'"
    try:
        version_str = run_cmd(shlex.split(cmd))[0].strip()
    except subprocess.SubprocessError:
        return (
            CheckState.FAILED,
            f"Unable to connect to the Docker daemon (checked with\n"
            f"{cmd!r}).\n"
            f"This could be because it isn't running, or due to insufficient permissions.\n"
            f"See installation instructions at https://docs.docker.com/engine/install/.",
        )

    version_match = re.match(r'"(\d+\.\d+(?:\.\d+)?)(?:\+.*)?"', version_str)
    if not version_match:
        return (
            CheckState.ERROR,
            f"Unable to parse Docker server version from\n"
            f"{cmd!r}.\n"
            f"At least version 18.0 is required for XRd.",
        )
    version = version_match.group(1)

    if int(version.split(".")[0]) < 18:
        return (
            CheckState.FAILED,
            f"Docker version must be at least 18.0, current server version is {version}.\n"
            f"See installation instructions at https://docs.docker.com/engine/install/.",
        )

    return CheckState.SUCCESS, f"running, version {version}"


def check_supports_d_type() -> CheckFuncReturn:
    """Check Docker is using a filesystem that supports d_type."""
    cmd = "docker info"
    try:
        output = run_cmd(shlex.split(cmd))[0]
    except subprocess.SubprocessError:
        return (
            CheckState.ERROR,
            f"{cmd!r} command failed.\n"
            f"Unable to check filesystem support for d_type (directory entry type).\n"
            f"This is required for XRd to avoid issues with creating and deleting files.",
        )
    if "Supports d_type: true" not in output:
        return (
            CheckState.FAILED,
            "Docker is using a backing filesystem that does not support d_type\n"
            "(directory entry type).\n"
            "This is required for XRd to avoid issues with creating and deleting files.",
        )
    return None


# -------------------------------------
# XR compose checks
# -------------------------------------


def check_docker_compose() -> CheckFuncReturn:
    """Check that the docker-compose version is 1.18.x or higher."""
    plugin_cmd = "docker compose version"
    standalone_cmd = "docker-compose --version"
    for cmd in (plugin_cmd, standalone_cmd):
        try:
            # Use a longer than default timeout as this command has been known to
            # time out.
            version_str = run_cmd(shlex.split(cmd), timeout=10)[0].strip()
            break
        except (FileNotFoundError, subprocess.SubprocessError):
            pass
    else:
        return (
            CheckState.FAILED,
            f"Docker Compose not found (checked with {plugin_cmd!r} and {standalone_cmd!r}).\n"
            f"Launching XRd topologies with xr-compose requires docker-compose.\n"
            f"See installation instructions at https://docs.docker.com/compose/install/.",
        )

    version_match = re.match(
        r"(?:docker-compose|Docker Compose) version v?(\d+\.\d+(?:\.\d+)?)",
        version_str,
    )
    if not version_match:
        return (
            CheckState.ERROR,
            "Unable to parse Docker Compose version, at least version 1.18 is required.",
        )
    version = version_match.group(1)
    version_tuple = tuple(int(x) for x in version.split("."))

    if version_tuple < (1, 18):
        return (
            CheckState.FAILED,
            f"Docker Compose version must be at least 1.18, current version is {version}.\n"
            f"See installation instructions at https://docs.docker.com/compose/install/.",
        )

    return CheckState.SUCCESS, f"version {version}"


def check_pyyaml_installed() -> CheckFuncReturn:
    """Check that the pyyaml package is installed for use by xr-compose."""
    try:
        import yaml  # pylint: disable=unused-import
    except ImportError:
        return (
            CheckState.FAILED,
            "PyYAML Python package not installed - required for running xr-compose.\n"
            "Install with 'python3 -m pip install pyyaml'.",
        )
    return CheckState.SUCCESS, "installed"


def check_bridge_iptables() -> CheckFuncReturn:
    """Check that bridge-nf-call-iptables are disabled."""
    for setting in ["bridge-nf-call-iptables", "bridge-nf-call-ip6tables"]:
        base_path = "/proc/sys/net/bridge"
        path = f"{base_path}/{setting}"
        long_msg = (
            "For xr-compose to be able to use Docker bridges, bridge IP tables must\n"
            "be disabled. Note that there may be security considerations associated\n"
            "with doing so.\n"
            "Bridge IP tables can be disabled by setting the kernel parameters\n"
            "net.bridge.bridge-nf-call-iptables and net.bridge.bridge-nf-call-ip6tables\n"
            "to 0. These can be modified by adding 'net.bridge.bridge-nf-call-iptables=0'\n"
            "and 'net.bridge.bridge-nf-call-ip6tables=0' to /etc/sysctl.conf or in a\n"
            "dedicated conf file under /etc/sysctl.d/.\n"
            "For a temporary fix, run:\n"
            "  sysctl -w net.bridge.bridge-nf-call-iptables=0\n"
            "  sysctl -w net.bridge.bridge-nf-call-ip6tables=0"
        )
        try:
            with open(path, "r", encoding="utf-8") as f:
                val = int(f.read().strip())
        except Exception:
            return (
                CheckState.ERROR,
                f"Failed to read iptables settings under {base_path}/.\n"
                + long_msg,
            )

        if val != 0:
            return CheckState.FAILED, long_msg

    return CheckState.SUCCESS, "disabled"


# -------------------------------------
# AWS checks
# -------------------------------------


def check_aws_cmdline() -> CheckFuncReturn:
    """Check that the expected args are in the cmdline."""

    # Expected values are as set during AMI creation by the XRd packer tool.
    # See https://github.com/ios-xr/xrd-packer

    with open("/proc/cmdline", "r", encoding="utf-8") as f:
        cmdline = f.read().strip().split()

    cmdline_args = {k: v for k, _, v in (x.partition("=") for x in cmdline)}

    # Check the args with known expected values
    expected_arg_values = {
        "nohz": "on",
        "skew_tick": "1",
        "intel_pstate": "disable",
        "tsc": "reliable",
        "nosoftlockup": "",
        "hugepagesz": "1G",
        "default_hugepagesz": "1G",
    }
    for arg, expected_value in expected_arg_values.items():
        if arg not in cmdline_args:
            return (
                CheckState.FAILED,
                f"Expected arg {arg} not found in cmdline",
            )
        if expected_value and cmdline_args[arg] != expected_value:
            return (
                CheckState.FAILED,
                f"Expected arg {arg} to be {expected_value} but found "
                f"{cmdline_args[arg]}",
            )

    # Check isolated cores-related args
    for arg in ["nohz_full", "isolcpus", "rcu_nocbs"]:
        if arg not in cmdline_args:
            return (
                CheckState.FAILED,
                f"Expected arg {arg} not found in cmdline",
            )
    if (
        cmdline_args["nohz_full"] != cmdline_args["isolcpus"]
        or cmdline_args["nohz_full"] != cmdline_args["rcu_nocbs"]
        or cmdline_args["isolcpus"] != cmdline_args["rcu_nocbs"]
    ):
        return (
            CheckState.FAILED,
            "Expected nohz_full, isolcpus and rcu_nocbs to all be the same, "
            f"but found nohz_full={cmdline_args['nohz_full']}, isolcpus="
            f"{cmdline_args['isolcpus']}, rcu_nocbs="
            f"{cmdline_args['rcu_nocbs']}",
        )

    # Check other args with unknown expected values
    for arg in ["irqaffinity", "hugepages"]:
        if arg not in cmdline_args:
            return (
                CheckState.FAILED,
                f"Expected arg {arg} not found in cmdline",
            )

    # Check the isolated and irqaffinity cores do not overlap
    isolated_with_range = cmdline_args["isolcpus"].split(",")
    isolated_cores = set()
    for c in isolated_with_range:
        if "-" in c:
            start, end = c.split("-")
            for i in range(int(start), int(end) + 1):
                isolated_cores.add(i)
        else:
            isolated_cores.add(int(c))
    irqaffinity_with_range = cmdline_args["irqaffinity"].split(",")
    irqaffinity = set()
    for c in irqaffinity_with_range:
        if "-" in c:
            start, end = c.split("-")
            for i in range(int(start), int(end) + 1):
                irqaffinity.add(i)
        else:
            irqaffinity.add(int(c))
    if isolated_cores & irqaffinity:
        return (
            CheckState.FAILED,
            "Expected isolcpus and irqaffinity to be disjoint, but found "
            f"isolcpus={cmdline_args['isolcpus']} and "
            f"irqaffinity={cmdline_args['irqaffinity']}",
        )

    if len(isolated_cores) < MIN_CPU_CORES_AVAILABLE:
        return (
            CheckState.FAILED,
            "At least 2 isolated cores are required",
        )

    return (
        CheckState.SUCCESS,
        "Expected cmdline args found with isolated cores "
        f"{cmdline_args['isolcpus']}",
    )


class Check(NamedTuple):
    """A check for some host capability."""

    name: str
    func: Callable[[], CheckFuncReturn]
    deps: List[str]


BASE_CHECKS = [
    Check("CPU architecture", check_arch, []),
    Check("CPU cores", check_cpu_cores, []),
    Check("Kernel version", check_kernel_version, []),
    Check(
        "Base kernel modules", check_base_kernel_modules, ["Kernel version"]
    ),
    Check("Cgroups", check_cgroups, []),
    Check(
        "Inotify max user instances",
        functools.partial(check_inotify_limits, "max_user_instances"),
        [],
    ),
    Check(
        "Inotify max user watches",
        functools.partial(check_inotify_limits, "max_user_watches"),
        [],
    ),
    Check("Socket kernel parameters", check_socket_parameters, []),
    Check("UDP kernel parameters", check_udp_parameters, []),
    Check("Core pattern", check_core_pattern, []),
    Check("ASLR", check_userspace_aslr, []),
    Check("Linux Security Modules", check_linux_security_modules, []),
    Check("Kernel module parameters", check_modules_expected_params, []),
]

CONTROL_PLANE_CHECKS = [
    Check(
        "RAM", functools.partial(check_ram, XRD_CP_RAM_GB_PER_CONTAINER), []
    ),
]

VROUTER_CHECKS = [
    Check("CPU extensions", check_cpu_extensions, []),
    Check(
        "RAM", functools.partial(check_ram, VROUTER_RAM_GB_PER_CONTAINER), []
    ),
    Check("Hugepages", check_hugepages, []),
    Check("Interface kernel driver", check_interface_kernel_driver, []),
    Check("IOMMU", check_iommu, ["Interface kernel driver"]),
    Check("PCI devices", check_pci_devices, ["Interface kernel driver"]),
    Check("Shared memory pages max size", check_shmem_pages_max_size, []),
    Check("Real-time Group Scheduling", check_realtime_group_sched, []),
]

DOCKER_CHECKS = [
    Check("Docker client", check_docker_client, []),
    Check("Docker daemon", check_docker_daemon, ["Docker client"]),
    Check("Docker supports d_type", check_supports_d_type, ["Docker daemon"]),
]

XR_COMPOSE_CHECKS = [
    Check("docker-compose", check_docker_compose, []),
    Check("PyYAML", check_pyyaml_installed, []),
    Check("Bridge iptables", check_bridge_iptables, []),
]

CONTROL_PLANE_AWS_CHECKS: List[Check] = []

VROUTER_AWS_CHECKS = [
    Check("Cmdline arguments", check_aws_cmdline, []),
]

PLATFORM_CHECKS_MAP: Mapping[str, List[Check]] = {
    "xrd-control-plane": CONTROL_PLANE_CHECKS,
    "xrd-vrouter": VROUTER_CHECKS,
}
EXTRA_CHECKS_MAP: Mapping[str, List[Check]] = {
    "docker": DOCKER_CHECKS,
    "xr-compose": XR_COMPOSE_CHECKS,
}
PLATFORM_AWS_CHECKS_MAP: Mapping[str, List[Check]] = {
    "xrd-control-plane-aws": CONTROL_PLANE_AWS_CHECKS,
    "xrd-vrouter-aws": VROUTER_AWS_CHECKS,
}

# -----------------------------------------------------------------------------
# Main
# -----------------------------------------------------------------------------


def print_check_status_msg(
    name: str, status: CheckState, msg: Optional[str]
) -> None:
    if status is CheckState.SUCCESS:
        colour = green
        status_word = "PASS"
    elif status is CheckState.WARNING:
        colour = yellow
        status_word = "WARN"
    elif status is CheckState.SKIPPED:
        colour = yellow
        status_word = "SKIP"
    elif status is CheckState.FAILED:
        colour = red
        status_word = "FAIL"
    elif status is CheckState.ERROR:
        colour = red
        status_word = "ERROR"
    elif status is CheckState.NEUTRAL:
        colour = cyan
        status_word = "INFO"
    else:
        assert False

    output = f"{status_word:>5} -- {name}"
    if msg and len(msg) < 32:
        output += f" ({msg})"
    elif msg:
        output += "\n" + textwrap.indent(msg, "         ")

    print(colour(output))


def perform_checks(checks: List[Check]) -> Mapping[str, CheckState]:
    """
    Perform host checks.

    :param checks:
        Checks to run through.
    :return:
        A mapping of check names and the check state.
    """
    results: Dict[str, CheckState] = {}
    msg: Optional[str]

    for name, check_fn, deps in checks:
        # Only run this test if previous dependent tests were successful.
        if not any(results[dep].is_failure() for dep in deps):
            try:
                ret = check_fn()
                if ret:
                    status, msg = ret
                else:
                    status = CheckState.SUCCESS
                    msg = None
            except Exception as e:
                status = CheckState.ERROR
                msg = f"Unexpected error: {e}"
        else:
            status = CheckState.SKIPPED
            msg = "Skipped due to failed checks: {}".format(", ".join(deps))
        print_check_status_msg(name, status, msg)

        results[name] = status

    return results


class ExtraResults(NamedTuple):
    """The results of any extra checks."""

    supported: Set[str]
    not_supported: Set[str]
    errored: Set[str]
    warned: Set[str]


def run_if_extra_checks(
    extra_checks: Optional[List[str]] = None,
) -> ExtraResults:
    """
    Run the specified extra checks, printing the results.
    :param extra_checks:
        List of extra checks to perform.
    :returns:
        NamedTuple of sets of checks that succeeded, failed, errored and warned.
    """
    extras_supported = set()
    extras_not_supported = set()
    extras_errored = set()
    extras_warned = set()

    if extra_checks:
        print("")  # insert a newline
        print_heading("Extra checks")
        for extra_check in sorted(extra_checks):
            print_subheading(f"{extra_check} checks")
            extra_results = perform_checks(EXTRA_CHECKS_MAP[extra_check])

            if any(check.is_failure() for check in extra_results.values()):
                extras_not_supported.add(extra_check)
            elif any(c is CheckState.ERROR for c in extra_results.values()):
                extras_errored.add(extra_check)
            elif any(c is CheckState.WARNING for c in extra_results.values()):
                extras_warned.add(extra_check)
            else:
                extras_supported.add(extra_check)

    return ExtraResults(
        extras_supported,
        extras_not_supported,
        extras_errored,
        extras_warned,
    )


def print_extra_checks_summary(extra_results: ExtraResults) -> None:
    """
    Print a summary of the extra checks that passed and failed.
    :param extras_results:
        The results of the extra checks.
    """
    print(f"{DASHED_LINE}")
    if extra_results.supported:
        print(
            "Extra checks passed: "
            + ", ".join(sorted(extra_results.supported))
        )
    if extra_results.not_supported:
        print(
            "Extra checks failed: "
            + ", ".join(sorted(extra_results.not_supported))
        )
    if extra_results.errored:
        print(
            "Extra checks errored: " + ", ".join(sorted(extra_results.errored))
        )
    if extra_results.warned:
        print(
            "Extra checks warned: " + ", ".join(sorted(extra_results.warned))
        )


def run_checks_specific_platform(
    platform: str, extra_checks: List[str]
) -> int:
    """
    Run checks for the given platform (including the base checks that are
    required for all platforms).

    :param platform:
        The XR platform.
    :param extra_checks:
        A list of the extra checks.
    :return:
        EXIT_SUCCESS if all checks were successful
        EXIT_ERROR if there are any failures, warnings or errors (including
            extra checks)
    """

    print_heading(f"Platform checks - {platform}")
    plat_results = list(
        perform_checks(BASE_CHECKS + PLATFORM_CHECKS_MAP[platform]).values(),
    )
    # If Amazon Linux is detected, run AWS host checks
    if is_amazon_linux() and PLATFORM_AWS_CHECKS_MAP[f"{platform}-aws"]:
        print_subheading("AWS host checks")
        al_results = perform_checks(PLATFORM_AWS_CHECKS_MAP[f"{platform}-aws"])
        plat_results += list(al_results.values())
    plat_failure = any(check.is_failure() for check in plat_results)
    plat_error = any(c is CheckState.ERROR for c in plat_results)
    plat_warning = any(c is CheckState.WARNING for c in plat_results)

    extra_results = run_if_extra_checks(extra_checks)

    # Print a summary of what is and is not supported
    print(f"\n{DOUBLE_DASHED_LINE}")
    if plat_failure:
        print(f"!! Host NOT set up correctly for {platform} !!")
    elif plat_error:
        print(
            "!! One or more platform checks could not be performed, see errors above !!"
        )
    elif plat_warning:
        print(
            "!! One or more platform checks resulted in a warning, see warnings above !!"
        )
    else:
        print(f"Host environment set up correctly for {platform}")
    if extra_checks:
        print_extra_checks_summary(extra_results)
    print(f"{DOUBLE_DASHED_LINE}")

    if (
        plat_failure
        or plat_error
        or extra_results.not_supported
        or extra_results.errored
        or plat_warning
        or extra_results.warned
    ):
        rc = EXIT_ERROR
    else:
        rc = EXIT_SUCCESS

    return rc


def run_checks_all_platforms(extra_checks: List[str]) -> int:
    """
    Run checks for all platforms and report which platforms are supported.

    :return:
        EXIT_SUCCESS if all checks were successful
        EXIT_ERROR if there are any failures, warnings or errors (including
            extra tests)
    """
    platforms_supported: Set[str] = set()
    platforms_not_supported: Set[str] = set()
    platforms_errored: Set[str] = set()
    platforms_warned: Set[str] = set()

    print_heading("Platform checks")
    print_subheading("base checks")
    base_results = perform_checks(BASE_CHECKS)
    for platform, checks in PLATFORM_CHECKS_MAP.items():
        print_subheading(f"{platform} checks")
        plat_results = perform_checks(checks)
        base_and_plat_results = list(base_results.values()) + list(
            plat_results.values()
        )
        # If Amazon Linux is detected, run AWS host checks
        if is_amazon_linux() and PLATFORM_AWS_CHECKS_MAP[f"{platform}-aws"]:
            print_subheading(f"AWS host checks for {platform}")
            al_results = perform_checks(
                PLATFORM_AWS_CHECKS_MAP[f"{platform}-aws"]
            )
            base_and_plat_results += list(al_results.values())
        if any(result.is_failure() for result in base_and_plat_results):
            platforms_not_supported.add(platform)
        elif any(
            result is CheckState.ERROR for result in base_and_plat_results
        ):
            platforms_errored.add(platform)
        elif any(
            result is CheckState.WARNING for result in base_and_plat_results
        ):
            platforms_warned.add(platform)
        else:
            platforms_supported.add(platform)

    extra_results = run_if_extra_checks(extra_checks)

    # Print a summary of what is and is not supported
    print(f"\n{DOUBLE_DASHED_LINE}")
    if platforms_supported:
        print(
            "XR platforms supported: " + ", ".join(sorted(platforms_supported))
        )
    if platforms_not_supported:
        print(
            "!! XR platforms NOT supported: "
            + ", ".join(sorted(platforms_not_supported))
            + " !!"
        )
    if platforms_errored:
        print(
            "!! One or more platform checks could not be performed for XR platforms: !!"
            + "\n      "
            + ",\n      ".join(sorted(platforms_errored))
            + "\n   See errors above."
        )
    if platforms_warned:
        print(
            "!! One or more platform checks resulted in a warning for XR platforms: !!"
            + "\n      "
            + ",\n      ".join(sorted(platforms_warned))
            + "\n   See warnings above."
        )

    # Print the result of any extra checks
    if extra_checks:
        print_extra_checks_summary(extra_results)
    print(f"{DOUBLE_DASHED_LINE}")

    if (
        platforms_not_supported
        or platforms_errored
        or extra_results.not_supported
        or extra_results.errored
        or platforms_warned
        or extra_results.warned
    ):
        rc = EXIT_ERROR
    else:
        rc = EXIT_SUCCESS

    return rc


def parse_args(argv: List[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "-p",
        "--platform",
        choices=["xrd-control-plane", "xrd-vrouter"],
        required=False,
        help="specify the XR platform to run host-check for",
    )
    parser.add_argument(
        "-e",
        "--extra-checks",
        nargs="+",
        choices=["docker", "xr-compose"],
        required=False,
        help="specify any extra checks to run",
    )
    args = parser.parse_args(argv)

    return args


def main(argv: List[str]) -> NoReturn:
    args = parse_args(argv)
    if args.platform:
        rc = run_checks_specific_platform(args.platform, args.extra_checks)
    else:
        rc = run_checks_all_platforms(args.extra_checks)
    sys.exit(rc)


if __name__ == "__main__":
    try:
        main(sys.argv[1:])
    except KeyboardInterrupt:
        print("Exiting on Ctrl+C")
        sys.exit(1)
